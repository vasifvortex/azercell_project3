# DataMinds'25 ML Predictor - Backend API

ğŸš€ A high-performance FastAPI backend service for machine learning predictions with async file processing and comprehensive error handling.

## ğŸŒŸ Features

- **ğŸ”¥ FastAPI Framework**: Modern, fast web framework with automatic API documentation
- **ğŸ“ Multi-format Support**: CSV, Excel (.xlsx, .xls) file processing
- **âš¡ Async Processing**: Non-blocking file uploads and processing
- **ğŸŒ CORS Enabled**: Cross-origin resource sharing for frontend integration
- **ğŸ“Š Health Monitoring**: Built-in health check endpoint
- **ğŸ•’ Timezone Support**: UTC and Baku timezone tracking
- **ğŸ›¡ï¸ Error Handling**: Comprehensive exception handling and logging
- **ğŸ“ Auto Documentation**: Interactive API docs via Swagger UI
- **ğŸ³ Container Ready**: Fully dockerized with UV dependency management

## ğŸ› ï¸ Technology Stack

- **Web Framework**: FastAPI 0.100+
- **Async Runtime**: Uvicorn ASGI server
- **Data Processing**: Custom ML prediction pipeline
- **File Handling**: Async file upload processing
- **Logging**: Python logging with structured output
- **Dependency Management**: UV (ultra-fast Python package installer)
- **Containerization**: Docker build


## ğŸ—ï¸ Architecture

### Project Structure
------------

    â”œâ”€â”€ LICENSE
    â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
    â”œâ”€â”€ data
    â”‚   â”œâ”€â”€ external       <- Data from third party sources.
    â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
    â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
    â”‚
    â”œâ”€â”€ models             <- Trained and serialized models, model predictions, or model summaries
    â”‚
    â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    â”‚                         the creator's initials, and a short `-` delimited description, e.g.
    â”‚                         `1.0-jqp-initial-data-exploration`.
    â”‚
    â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
    â”‚
    â”œâ”€â”€ uv.lock   <- The requirements file for reproducing the analysis environment, e.g.
    â”‚                         generated with `uv lock > uv.lock`
    â”‚
    â”œâ”€â”€ pyptoject.toml    <- makes project uv installable (uv installs) so src can be imported
    â”œâ”€â”€ src                <- Source code for use in this project.
    â”‚   â”œâ”€â”€ __init__.py    <- Makes src a Python module
    â”‚   â”‚
    â”‚   â”œâ”€â”€ data           <- Scripts to download or generate data
    â”‚   â”‚   â””â”€â”€ make_dataset.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ features       <- Scripts to turn raw data into features for modeling
    â”‚   â”‚   â””â”€â”€ build_features.py
    â”‚   â”‚
    â”‚   â”œâ”€â”€ models         <- Scripts to train models and then use trained models to make
    â”‚   â”‚   â”‚                 predictions
    â”‚   â”‚   â”œâ”€â”€ predict_model.py
    â”‚   â”‚   â””â”€â”€ train_model.py
    â”‚   â”‚
    â”‚   â””â”€â”€ visualization  <- Scripts to create exploratory and results oriented visualizations
    â”‚       â””â”€â”€ visualize.py
    â”œâ”€â”€ app.py                    # FastAPI application entry point
    â”œâ”€â”€ Dockerfile                # Container build instructions
    â”œâ”€â”€ pyproject.toml            # UV project configuration & dependencies
    â”œâ”€â”€ uv.lock                   # Locked dependency versions
    â””â”€â”€ README.md                 # This file

--------


### Key Components

1. **FastAPI Application**: Main web server with CORS middleware
2. **Prediction Pipeline**: ML model inference via `src.models.predict_model`
3. **File Processor**: Async file upload and validation
4. **Health Monitor**: System status and timezone tracking
5. **Error Handler**: Comprehensive exception management
6. **Logger**: Structured logging for debugging and monitoring

## ğŸ³ Docker Setup

This backend API is fully containerized and designed to work as part of a Docker Compose stack.

## ğŸš€ Quick Start

### Option 1: Docker Compose (Recommended)

The backend is part of a larger Docker Compose application:

```bash
# Run the entire stack
docker-compose up -d

# View logs
docker-compose logs backend

# Stop the stack
docker-compose down
```

The API will be available at `http://localhost:8000`

### Option 2: Standalone Docker

```bash
# Build the backend image
docker build -t dataminds-backend .

# Run the container
docker run -p 8000:8000 \
  -e HOST=0.0.0.0 \
  -e PORT=8000 \
  dataminds-backend
```

### Option 3: Local Development

For local development without Docker:

```bash
# Install UV (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Install dependencies
uv sync

# Run the application
uv run uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

## ğŸ“¡ API Endpoints

### Health Check

**GET** `/health`

Returns system status and timezone information.

**Response:**
```json
{
  "status": "healthy",
  "utc_time": "2024-08-14T10:30:00.000000+00:00",
  "baku_time": "2024-08-14T14:30:00.000000+04:00"
}
```

### Make Predictions

**POST** `/predict`

Upload a file and receive ML predictions.

**Request:**
- **Content-Type**: `multipart/form-data`
- **Body**: Form data with file upload
  - `file`: CSV or Excel file (.csv, .xlsx, .xls)

**Response:**
```json
{
  "status": "success",
  "message": "Predictions generated successfully",
  "data": {
    "predictions": [0.85, 0.92, 0.78, 0.91],
    "num_predictions": 4,
    "processing_time_seconds": 0.234
  }
}
```

**Error Response:**
```json
{
  "detail": "Invalid file format. Please upload CSV or Excel files only."
}
```

### Interactive API Documentation

- **Swagger UI**: `http://localhost:8000/docs`

## ğŸ”§ Configuration

### Environment Variables

```bash
# Server configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Logging
LOG_LEVEL=INFO

# Application settings
APP_NAME="FastAPI Backend server for ML project"
APP_VERSION="1.0.0"
```

### Docker Compose Integration

```yaml
# Example docker-compose.yml snippet
services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    networks:
      - safe_networks
    restart: always
    image: backend
    container_name: backend
    volumes:
      - ./backend:/app
      - backend_venv:/app/.venv
    ports:
      - "8000:8000"
```

### CORS Configuration

The API is configured to accept requests from any origin:

```python
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Configure for production
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```